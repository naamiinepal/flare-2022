{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2afdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.config import print_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb4b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1812c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e41790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "from glob import glob\n",
    "import os.path\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, Orientationd, Spacingd,\n",
    "    ScaleIntensityRanged, CropForegroundd, RandCropByLabelClassesd,\n",
    "    RandAffined, ToTensord\n",
    ")\n",
    "\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "\n",
    "\n",
    "NUM_LABELS = 13\n",
    "\n",
    "ROI_SIZE = (128, 128, 64)\n",
    "\n",
    "class FlareDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int = 32,\n",
    "        dev_ratio: float = 0.2,\n",
    "        cache_ds: bool = True,\n",
    "        max_workers: int = 4,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._dict_keys = (\"image\", \"label\")\n",
    "        \n",
    "        data_dir = \"/mnt/HDD2/flare2022/datasets/FLARE2022\"\n",
    "        self.supervised_dir = os.path.join(data_dir, \"Training\", \"FLARE22_LabeledCase50\")\n",
    "        \n",
    "        self.num_workers = min(os.cpu_count(), max_workers)\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        if stage is None or stage == \"fit\":\n",
    "            images = self.get_image_paths(\"images\")\n",
    "            labels = self.get_image_paths(\"labels\")\n",
    "\n",
    "            data_dicts = tuple(\n",
    "                {\"image\": img, \"label\": lab} for img, lab in zip(images, labels)\n",
    "            )\n",
    "            \n",
    "            train_files, val_files = train_test_split(data_dicts, test_size=self.hparams.dev_ratio)\n",
    "            \n",
    "            self.crop_num_samples = 4\n",
    "            \n",
    "            train_transforms = self.get_transform(\n",
    "                    RandCropByLabelClassesd(\n",
    "                        keys=self._dict_keys,\n",
    "                        label_key=\"label\",\n",
    "                        spatial_size=ROI_SIZE,\n",
    "                        num_samples=self.crop_num_samples,\n",
    "                        num_classes=NUM_LABELS + 1\n",
    "                    ),\n",
    "                    # user can also add other random transforms\n",
    "#                     RandAffined(\n",
    "#                         keys=keys,\n",
    "#                         mode=('bilinear', 'nearest'),\n",
    "#                         prob=1.0,\n",
    "#                         rotate_range=(0, 0, math.pi/15),\n",
    "#                         scale_range=(0.1, 0.1, 0.1)\n",
    "#                     )\n",
    "            )\n",
    "            val_transforms = self.get_transform()\n",
    "            \n",
    "            self.train_ds = self.get_dataset(train_files, train_transforms)\n",
    "            \n",
    "            self.val_ds = self.get_dataset(val_files, val_transforms)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=self.hparams.batch_size // self.crop_num_samples ,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_ds,\n",
    "            batch_size=1, # Because the images do not align and are not cropped\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    def get_image_paths(self, baseDir: str):\n",
    "        image_paths = glob(os.path.join(self.supervised_dir, baseDir, \"*.nii.gz\"))\n",
    "        image_paths.sort()\n",
    "        return image_paths\n",
    "\n",
    "    def get_transform(self, *random_transforms):\n",
    "        keys = self._dict_keys\n",
    "        return Compose((\n",
    "            LoadImaged(keys=keys),\n",
    "            EnsureChannelFirstd(keys=keys),\n",
    "            Orientationd(keys=keys, axcodes=\"RAS\"),\n",
    "    #         Spacingd(keys=keys, pixdim=(\n",
    "    #             1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "    #         ScaleIntensityRanged(\n",
    "    #             \"image\", a_min=-57, a_max=164,\n",
    "    #             b_min=0.0, b_max=1.0, clip=True,\n",
    "    #         ),\n",
    "            CropForegroundd(keys=keys, source_key=\"image\"),\n",
    "            *random_transforms,\n",
    "            ToTensord(keys=keys),\n",
    "        ))\n",
    "    \n",
    "    def get_dataset(self, *dataset_args):\n",
    "        return (\n",
    "            CacheDataset(*dataset_args, num_workers=self.num_workers)\n",
    "            if self.hparams.cache_ds else\n",
    "            Dataset(*dataset_args)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b031db",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = FlareDataModule(batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c1058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a239cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule.train_ds[0][0][\"label\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db66c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule.train_ds[0][0][\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "import torch\n",
    "from torchmetrics.functional import dice_score\n",
    "\n",
    "class Segmentor(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate: float = 1e-4,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.model = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=NUM_LABELS + 1,\n",
    "            channels=(4, 8, 16),\n",
    "            strides=(2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=\"batch\",\n",
    "            bias=False # no need for bias for batch norm\n",
    "        )\n",
    "        \n",
    "        self.criterion = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        return self.model(image)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        label = batch[\"label\"]\n",
    "        image = batch[\"image\"]\n",
    "        \n",
    "        output = self(image)\n",
    "        \n",
    "        score = dice_score(output, label, bg=False)\n",
    "        \n",
    "        self.log(\"train_dice_score\", score, prog_bar=True)\n",
    "        \n",
    "        loss = self.criterion(output, label)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        label = batch[\"label\"]\n",
    "        image = batch[\"image\"]\n",
    "        \n",
    "        roi_size = ROI_SIZE\n",
    "        sw_batch_size = 4\n",
    "        output = sliding_window_inference(image, roi_size, sw_batch_size, self, overlap=0.1)\n",
    "        \n",
    "        score = dice_score(output, label, bg=False)\n",
    "        \n",
    "        self.log(\"val_dice_score\", score, batch_size=1, prog_bar=True)\n",
    "        \n",
    "        loss = self.criterion(output, label)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, batch_size=1)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), self.hparams.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6fadb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Segmentor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdc7a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = pl.loggers.WandbLogger(\n",
    "    project=\"flare\",\n",
    "    name=\"unet\",\n",
    ")\n",
    "\n",
    "# saves top-K checkpoints based on \"val_loss\" metric\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_top_k=10,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    dirpath=\"checkpoints\",\n",
    "    save_weights_only=True,\n",
    "    filename=\"unet-{epoch:02d}-{val_loss:.2f}\",\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=50,\n",
    "    gpus=[1],\n",
    "    log_every_n_steps=5,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.inference_mode():\n",
    "#     batch = next(iter(datamodule.train_dataloader()))\n",
    "    \n",
    "#     label = batch[\"label\"]\n",
    "#     image = batch[\"image\"]\n",
    "    \n",
    "#     preds = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa55fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b9b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f2624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice_score(preds, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055cb30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
