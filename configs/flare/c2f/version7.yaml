seed_everything: 42
trainer:
  logger:
      class_path: pytorch_lightning.loggers.TensorBoardLogger
      init_args:
          save_dir: c2f_logs
          name: unet-l5-s16-256
          log_graph: True
          default_hp_metric: False
  callbacks:
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        save_top_k: 10
        monitor: ${model.monitor}
        mode: min
        dirpath: checkpoints/c2f/unet-l5-s16-256
        save_weights_only: True
        filename: "{epoch:02d}-{val\/loss:.2f}"
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        monitor: ${model.monitor}
        patience: 40
        verbose: True
  devices: [0] # None can not be returned in multiple GPUs
  max_epochs: 200
  accelerator: "gpu"
  log_every_n_steps: 10
  accumulate_grad_batches: 64 # Actual batch size
  val_check_interval: 0.5
  # fast_dev_run: True
ckpt_path: null
model:
  class_path: models.c2f.C2FSegmentor
  init_args:
    coarse_model: null
    fine_model: null
    coarse_weights_path: null
    fine_weights_path: null
    is_coarse: false
    pseudo_threshold: 0.9
    unsup_weight: 1.0
    learning_rate: 0.03
    sw_batch_size: 4
    sw_overlap: 0.1
    sw_mode: gaussian
    plateu_patience: 2
    plateu_factor: 0.1
    momentum: 0.9
    monitor: val/loss
    do_post_process: true
    connectivity: null
data:
  class_path: datamodules.c2f_datamodule.C2FDataModule
  init_args:
    num_labels_with_bg: 14
    coarse_roi_size: [128, 128, 64]
    fine_roi_size: [192, 192, 96]
    intermediate_roi_size: [256, 256, 128]
    supervised_dir: /mnt/HDD2/flare2022/datasets/FLARE2022/Training/FLARE22_LabeledCase50
    semisupervised_dir: /mnt/HDD2/flare2022/datasets/FLARE2022/Training/Unlabeled
    val_ratio: 0.2
    do_semi: True
    semi_mu: null
    crop_num_samples: 4
    batch_size: 16
    ds_cache_type: null
    max_workers: 4
    pin_memory: true
