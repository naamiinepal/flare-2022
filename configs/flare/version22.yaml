seed_everything: 42
trainer:
  logger:
      class_path: pytorch_lightning.loggers.TensorBoardLogger
      init_args:
          save_dir: tb_logs
          name: unet-l7-s8-512-spacing-res3-semi
          version: DiceLossForeground
          log_graph: True
          default_hp_metric: False
  callbacks:
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        save_top_k: 10
        monitor: ${model.monitor}
        mode: min
        dirpath: checkpoints/unet-l7-s8-512-spacing-res3-semi
        save_weights_only: True
        filename: "{epoch:02d}-{val\/loss:.2f}"
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        monitor: ${model.monitor}
        patience: 40
        verbose: True
  devices: [0] # None can not be returned in multiple GPUs
  max_epochs: 50
  accelerator: "gpu"
  log_every_n_steps: 128
  accumulate_grad_batches: 64 # Actual batch size
  val_check_interval: 0.5
model:
  model:
    class_path: monai.networks.nets.UNet
    init_args:
      spatial_dims: 3
      in_channels: 1
      out_channels: ${data.num_labels_with_bg}
      channels: [8, 16, 32, 64, 128, 256, 512]
      strides: [2, 2, 2, 2, 2, 2]
      num_res_units: 3
      act: relu
  learning_rate: 0.03
  pseudo_threshold: 0.95
  unsup_weight: 1
  sw_batch_size: ${data.crop_num_samples}
  sw_overlap: 0.25
  plateu_patience: 3
  plateu_factor: 0.1
  monitor: val/loss
data:
  supervised_dir: /mnt/HDD2/flare2022/datasets/FLARE2022/Training/FLARE22_LabeledCase50
  semisupervised_dir: /mnt/HDD2/flare2022/datasets/FLARE2022/Training/Unlabeled
  do_semi: True
  semi_mu: 7
  num_labels_with_bg: 14
  val_ratio: 0.2
  crop_num_samples: 4
  batch_size: ${data.crop_num_samples}
  ds_cache_type: disk
  max_workers: 5
  roi_size: [128, 128, 64]
  pixdim: [2.5, 2.5, 2.5]
